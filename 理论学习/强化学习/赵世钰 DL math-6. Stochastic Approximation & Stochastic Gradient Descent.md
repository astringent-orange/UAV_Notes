
# Motivating
![[48d7774e-7e00-4057-952a-fbcfd9e2e483.png]]
回顾之前的内容 mean estimation，通过统计平均值去近似X的期望

如果求这个“统计平均值”？有两种方法
1. 通过真实采样，等所有数据收集完成，然后加在一起求平均，耗时长
2. 增量式方法，来几个计算几个
![[b8ce2642-5502-44b4-86ef-b6bf9dc54538.png]]
通过迭代的方法，每得到一个采样更新一次平均

![[7a9a27fd-561c-47e2-b345-896565cd7448.png]]
如果将迭代算法改成这样，是否还能收敛到期望值？当αk满足一定条件时是可以的。而这种算法也是SA和SGD的一种特殊形式。

# Robbins-monro algorithm
首先stochastic approximation表示了一大类随机且迭代的算法，且用于方程求解或进行优化问题，其特点在于不需要知道目标方程或表达式。而RM是SA开创的工作，而SGD是SA的一种特殊情况。

假设要求解以下这个方程，且不知道函数的表达式
![[ddcd63f0-a5d0-44fc-b7d7-237b40433822.png]]

RM算法如下
![[77bdcb5d-b994-43e9-bcdc-2130d18eeeeb.png]]
![[3dabef69-6d1f-489d-a7f3-823b7b8df096.png]]
不断通过迭代w，便最终可以得到g(w)=0的解。其中η表示噪音，而g(w, η)表示g(w)带噪音的观测，ak表示一个正因子；整个过程已知的只有输入的{w}和输出的带噪结果{g(w,η)}

当g(w)满足以下条件时RM算法是可以实现的
![[8ed025ab-45ed-4f92-9ec4-ad29dc65cd33.png]]
第一个条件g(w)的梯度要求为正且有界，即g(w)单调增；第二个条件如何解读：首先ak^2 和趋于无穷，表示ak最后一定会趋于0，而ak和趋于无穷要求不要收敛得太快；第三个条件，即η的均值为0，且方差有界。

更具体而言，对第二个条件进行讨论
首先，为什么说ak趋向于0是重要的呢？可以将上面的迭代公式写为以下形式，如果ak趋向于0，那么左边也趋向于0，表示wk+1和wk趋于相等
![[0f64b2c9-8a72-41a9-8805-4d66d4b22001.png]]
其次，为什么ak和等于无穷，即让ak不要太快到0，为什么这个式子重要？对于一开始的迭代公式逐项相加，有以下的形式。w1表示最初猜测的值，而w∞为最终的解w* ，当ak和是有界数时，这两者的差则也可能是一个有界的数，那么w1就不能随便，必须要求在w* 附近。
![[52625f82-3827-491b-9dce-23ea16663daf.png]]
最后，什么样的ak可以满足这两个条件呢？通常一个典型就是ak=1/k。但实际使用时，一般会让ak为一个很小的常数
![[0a0a4d20-5c52-44c5-8810-fbc3dc9c6c1c.png]]

回到一开始的mean estimation，当时说当ak满足一些条件时，wk仍然可以收敛到EX；这个算法其实可以看为RM
![[7a9a27fd-561c-47e2-b345-896565cd7448.png]]
考虑以下这样一个函数，目标是求g(w)=0，就相当于去求EX
![[bb2f049c-d918-4f67-bb1f-0c0d31611f57.png]]


![[63da20a9-b399-4997-8510-131aa2e53afc.png]]

# Stochastic gradient descent



# BGD MBGD SGD